# LEMAY.AI INTERVIEW QUESTIONS

Hello, human.

Your goal is to demonstrate your coding skills by creating a video recording of your answers to some general knowledge questions, writing an ML API demo using Docker, python3, and a bit of magic, and showing us your exploratory data analysis skills. Please spend minimal effort on graphics and UI, as this is not a test of your UI coding skills. Just don't stress on frontend stuff.

# 1) GENERAL KNOWLEDGE VIDEO DEMONSTRATION

- Please make a video recording of your answers to the questions in the notebook: https://github.com/lemay-ai/fizzbuzz/blob/main/Interview_Questions.ipynb
- Please share the video file with daniel@lemay.ai and matt@lemay.ai
- After you submit the video, proceed to steps 2 and 3, below.

# 2) MODEL DEPLOYMENT DEMONSTRATION
Please fork this repo (you may opt to share a private repo with us to preserve your privacy) and then do the following:
- Create a branch in your forked repo
- Create a container to process inference requests from any pretrained model in the huggingface model hub: https://huggingface.co/models
- Your solution should include server components to support multiple parallel incoming requests (e.g., NGINX/gunicorn)
- Create a notebook to demonstrate requests that POST to the container endpoint and print out the response
- Please explain why you have chosen this model as your demonstration

# 3) EXPLORATORY DATA ANALYSIS DEMONSTRATION
- Perform exploratory data analysis on any dataset in the huggingface datasets hub: https://huggingface.co/datasets
- Include a notebook that contains your analysis within the repository
- Please explain why you have chosen this dataset for your demonstration of exploratory data analysis

- Commit your code
- Create a pull request and you can approve it yourself and merge the branch into trunk
- Document the process for using your updated repo in README.md so that we can try out your demo ourselves
- Share the repo with the github users dcshapiro and elmathioso


# Solution:

## Model deployment:
### Files created for this step:
1) model_deployment.ipynb ----jupyter notebook to load and save the sentiment analysis model from hugging face
2) app.py --------------------FastAPI app used to make a simple web page
3) Dockerfile ----------------configurations for the docker
4) locustexec.py--------------for load testing parallel requests
5) container_connect.ipynb ---a simple notebook to test single requests and response
6) EDA.ipynb------------------data analysis on text data from hugging face
7) model----------------------this folder contains the pickled model

### Running and testing the project:
#### 1) Use the model_deployment.ipynb notebook to save the hugging face model as model.pkl in model folder, 
#### a simple sentiment analysis model is used for demonstration since it is fun to use and is quite interactable

#### 2) Next app.py file contains a simple FastAPI based app to receive requests
#### running app.py will start the app at http://0.0.0.0:80 address
#### for a more graphical view access this address http://0.0.0.0:80/docs
#### click > POST /state_analysis/ then click > try it out
#### enter tweet in text field and hit > execute
#### response is displayed below in response body block
#### same process can be done using the container_connect.ipynb

#### 3) to perform load test locust.exec.py file is used, open terminal (in the project folder , I used the PyCharm's terminal for everything)
#### run command 
: locust -f locustexec.py
#### CLI interface will give link  http://0.0.0.0:8089 , Click link > and enter number of user (ex. 100) spawn rate (ex. 1) and Host address as generated by app.py (ex. http://0.0.0.0:80)
#### click start swarming to start the test, all stats and charts are displayed there

#### 4) Now let's create the docker container, stop both locust and app.py execution
#### dockerfile is present in the directory, in CLI terminal enter the following commands

#### run this command to build docker image: lemay_test (name of image)
: docker build -t lemay_test .  

#### to start container : mytestcontainer (name of container) that runs at port 80
: docker run -d --name mytestcontainer -p 80:80 lemay_test

#### same step 2 and 3 can be repeated but this time while using the docker container

## EDA DEMONSTRATION

#### EDA.ipynb notebook uses a text corpus dataset from the hugging face
#### - dataset is loaded as pandas dataframe and checked for any missing or null rows
#### - all text converted to lowercase and all punctuations are removed
#### - then as last step a wordcloud os generated excluding the stopwords from the text